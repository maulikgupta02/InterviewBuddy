{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"RajatSachdeva5y_6m.pdf\")\n",
    "resume = loader.load()\n",
    "resume=\"\\n\".join(doc.page_content for doc in resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from docx2pdf import convert\n",
    "\n",
    "# convert(\"Draft_AI_LLM_Engineer.docx\")\n",
    "# convert(\"input.docx\", \"output.pdf\")\n",
    "# convert(\"my_docx_folder/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"JD/Draft_AI_LLM_Engineer.pdf\")\n",
    "jd = loader.load()\n",
    "jd=\"\\n\".join(doc.page_content for doc in jd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Agentic RAG Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Custom Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool for downloading the interview chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool name: store_history\n",
      "tool description: Download the chat history on the system\n",
      "tool arguments: {'interview_doc': {'title': 'Interview Doc', 'type': 'string'}, 'candidate': {'title': 'Candidate', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "import os\n",
    "\n",
    "@tool\n",
    "def store_history(interview_doc:str, candidate:str) -> str:\n",
    "    \"\"\"\n",
    "    Download the chat history on the system\n",
    "    \"\"\"\n",
    "\n",
    "    # function definition starts from here\n",
    "\n",
    "    directories=os.listdir()\n",
    "    if 'interview' not in directories:\n",
    "        os.mkdir('interview')\n",
    "\n",
    "    file_path=f\"interview/{candidate}.txt\"\n",
    "\n",
    "    with open(file_path,'w+') as file:\n",
    "        file.writelines(interview_doc)\n",
    "\n",
    "    return file_path\n",
    "\n",
    "\n",
    "print(\"tool name:\",store_history.name)\n",
    "print(\"tool description:\",store_history.description)\n",
    "print(\"tool arguments:\",store_history.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'interview/test.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_history(tool_input={'interview_doc':'test','candidate':'test'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool for testing against the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool name: get_report\n",
      "tool description: Test the interview chat against a benchmark and store the report\n",
      "tool arguments: {'questions': {'title': 'Questions', 'type': 'array', 'items': {}}, 'responses': {'title': 'Responses', 'type': 'array', 'items': {}}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_report(questions:list, responses:list) -> str:\n",
    "    \"\"\"\n",
    "    Test the interview chat against a benchmark and store the report \n",
    "    \"\"\"\n",
    "\n",
    "    rubrics=pd.read_csv(\"eval_rubrics.csv\")\n",
    "\n",
    "    # function definition starts here\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_4o_API_KEY\"),  \n",
    "    api_version = os.getenv(\"API_VERSION_4o\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_4o_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"You are a corporate interviewer responsible for grading the candidates according to their responses \\\n",
    "             This is the criterian for evaluation {rubrics}. \\\n",
    "\n",
    "             Question asked from the candidate: {questions[-1]}. \\\n",
    "             Response given by the candidate: {responses[-1]}. \\\n",
    "             Just give the scores without explaination under each criteria according to the relevance to the job. \\\n",
    "             Give answer in the following format: Relevance,4\\nAccuracy,3\\nClarity,3\\nDepth,2\\nLanguage Use,3\\nCompleteness,2 \n",
    " \"\"\"}])\n",
    "\n",
    "    score=response.choices[0].message.content\n",
    "    # score=score.replace(',',':')\n",
    "\n",
    "    return score\n",
    "\n",
    "            #  This is the candidate's resume: {resume}. \\\n",
    "            #  This is the job description: {jd}. \\\n",
    "\n",
    "print(\"tool name:\",get_report.name)\n",
    "print(\"tool description:\",get_report.description)\n",
    "print(\"tool arguments:\",get_report.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Relevance:1\\nAccuracy:1\\nClarity:1\\nDepth:1\\nLanguage Use:2\\nCompleteness:1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "score=get_report(tool_input={\n",
    "    'questions':[\"\"\"Sure, Rajat. Let's shift to another aspect of your experience mentioned in your resume.\n",
    "\n",
    "You have substantial experience with Computer Vision and specifically mentioned using YOLO for object detection.\n",
    "\n",
    "**Question: Can you explain the process of setting up and using a YOLO (You Only Look Once) model for object detection? How do you prepare your dataset, train the model, and evaluate its performance? What considerations do you keep in mind for optimizing the training process?**\"\"\"],\n",
    "    'responses':[\"\"\"can we end this now\n",
    "\"\"\"]})\n",
    "score_csv = StringIO(score)\n",
    "score=score.replace(',',':')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Relevance': 1,\n",
       " 'Accuracy': 1,\n",
       " 'Clarity': 1,\n",
       " 'Depth': 1,\n",
       " 'Language Use': 2,\n",
       " 'Completeness': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(score_csv,header=None)\n",
    "result_dict = df.set_index(0).to_dict()[1]\n",
    "result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question generating LLM as Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool name: ask_question\n",
      "tool description: LLM for generating a new question to be asked from the candidate\n",
      "tool arguments: {'resume': {'title': 'Resume', 'type': 'string'}, 'jd': {'title': 'Jd', 'type': 'string'}, 'chat_history': {'title': 'Chat History', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@tool\n",
    "def ask_question(resume:str, jd:str, chat_history:str) -> str:\n",
    "    \"\"\"\n",
    "    LLM for generating a new question to be asked from the candidate\n",
    "    \"\"\"\n",
    "\n",
    "    # function definition starts here\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_4o_API_KEY\"),  \n",
    "    api_version = os.getenv(\"API_VERSION_4o\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_4o_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"You are a corporate interviewer responsible for taking candidate interviews. \\\n",
    "             This is a technical round, hence you need to ask questions regarding relevant technologies. \\\n",
    "             You may ask some short syntax or a conceptual question. \\\n",
    "             This is the job description: {jd}. \\\n",
    "             This is the candidate's resume: {resume}. \\\n",
    "             This is the past interaction you had with the candidate: {chat_history}. \\\n",
    "             Either ask a review question on candidate's last reponse or ask a new question. \\\n",
    "             Make sure to only ask a single question. \\\n",
    "             The question needs to be relevant to the job description or the candidate's past experience.\"\"\"}])\n",
    "\n",
    "    question=response.choices[0].message.content\n",
    "\n",
    "    return question\n",
    "\n",
    "\n",
    "print(\"tool name:\",ask_question.name)\n",
    "print(\"tool description:\",ask_question.description)\n",
    "print(\"tool arguments:\",ask_question.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ask_question(resume: str, jd: str, chat_history: str) -> str - LLM for generating a new question to be asked from the candidate\\nstore_history(interview_doc: str, candidate: str) -> str - Download the chat history on the system'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "rendered_tools = render_text_description([ask_question,store_history])\n",
    "rendered_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Agent Implementation without langgraph***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interviewer: Thank you for detailing your extensive experience, Rajat. You've touched on a significant number of points related to AI, ML, and automation frameworks. Given that the job role includes responsibilities like designing novel LLM architectures and advanced machine learning models training using frameworks such as TensorFlow and PyTorch, could you please elaborate on any specific projects where you've designed or implemented custom LLM architectures or applied advanced deep learning techniques using TensorFlow or PyTorch? Can you provide details on the challenges you faced and how you addressed them?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_4o_API_KEY\"),  \n",
    "    api_version = os.getenv(\"API_VERSION_4o\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_4o_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "questions=[]\n",
    "responses=[]\n",
    "scores={}\n",
    "\n",
    "def handle_interview(jd, resume, initial_chat_history):\n",
    "    chat_history = initial_chat_history\n",
    "    while True:\n",
    "        decision = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"\n",
    "                You are a corporate interviewer responsible for taking candidate interviews. Decide whether to ask another question or end the conversation.\n",
    "                This is the job description: {jd}.\n",
    "                This is the candidate's resume: {resume}.\n",
    "                This is the past interaction you had with the candidate: {chat_history}.\n",
    "                Respond with 'ask' to ask another question or 'end' to end the conversation.\n",
    "                \"\"\"}]).choices[0].message.content\n",
    "        if decision == 'ask':\n",
    "            question = ask_question(tool_input={'resume':resume, 'jd':jd, 'chat_history':chat_history})\n",
    "            questions.append(question)\n",
    "            chat_history += f\"\\nInterviewer: {question}\"\n",
    "            print(f\"Interviewer: {question} \\n\")\n",
    "            # break ################################################# for testing\n",
    "            candidate_response = input(\"Candidate: \")\n",
    "            responses.append(candidate_response)\n",
    "\n",
    "            score=get_report(tool_input={'questions':questions,'responses':responses})\n",
    "\n",
    "            chat_history += f\"\\nCandidate: {candidate_response}\\n\"\n",
    "            chat_history += f\"\\nScore: {score.replace(',',':')}\\n\\n\\n\"\n",
    "\n",
    "            from io import StringIO\n",
    "            score_csv = StringIO(score)\n",
    "            temp_df=pd.read_csv(score_csv,header=None)\n",
    "            result_dict = temp_df.set_index(0).to_dict()[1]\n",
    "            for i in list(result_dict.keys()):\n",
    "                if i not in scores:\n",
    "                    scores[i]=[result_dict[i]]\n",
    "                else:\n",
    "                    scores[i].append(result_dict[i])\n",
    "\n",
    "        elif decision == 'end':\n",
    "            print(\"Interview ended.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Unexpected decision. Ending interview.\")\n",
    "            break\n",
    "\n",
    "    store_history(tool_input={'interview_doc':chat_history,'candidate':'test'})\n",
    "    scores.to_csv(\"reports/test.csv\",index=False)\n",
    "\n",
    "handle_interview(jd=jd, resume=resume, initial_chat_history=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Agent Implementation using langgraph***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: str\n",
    "    decision: str\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import os\n",
    "\n",
    "@tool\n",
    "def store_history(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Download the chat history on the system\n",
    "    \"\"\"\n",
    "\n",
    "    # function definition starts from here\n",
    "\n",
    "    directories=os.listdir()\n",
    "    if 'interview' not in directories:\n",
    "        os.mkdir('interview')\n",
    "\n",
    "    file_path=f\"interview/test.txt\"\n",
    "\n",
    "    with open(file_path,'w+') as file:\n",
    "        file.writelines(chat_history)\n",
    "\n",
    "    return {\"message\":\"chat history stored successfully\"}\n",
    "\n",
    "\n",
    "from langchain.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_report(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Test the interview chat against a benchmark and store the report \n",
    "    \"\"\"\n",
    "\n",
    "    rubrics=pd.read_csv(\"eval_rubrics.csv\")\n",
    "\n",
    "    # function definition starts here\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_4o_API_KEY\"),  \n",
    "    api_version = os.getenv(\"API_VERSION_4o\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_4o_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"You are a corporate interviewer responsible for grading the candidates according to their responses \\\n",
    "             This is the criterian for evaluation {rubrics}. \\\n",
    "\n",
    "             Question asked from the candidate: {state['question'][-1]}. \\\n",
    "             Response given by the candidate: {state['answer'][-1]}. \\\n",
    "             Just give the scores without explaination under each criteria according to the relevance to the job. \\\n",
    "             Give answer in the following format: Relevance,4\\nAccuracy,3\\nClarity,3\\nDepth,2\\nLanguage Use,3\\nCompleteness,2 \n",
    " \"\"\"}])\n",
    "\n",
    "    score=response.choices[0].message.content\n",
    "    # score=score.replace(',',':')\n",
    "\n",
    "    return score\n",
    "\n",
    "            #  This is the candidate's resume: {resume}. \\\n",
    "            #  This is the job description: {jd}. \\\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@tool\n",
    "def ask_question(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    LLM for generating a new question to be asked from the candidate\n",
    "    \"\"\"\n",
    "    print(\"generate question\")\n",
    "    # function definition starts here\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_4o_API_KEY\"),  \n",
    "    api_version = os.getenv(\"API_VERSION_4o\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_4o_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"You are a corporate interviewer responsible for taking candidate interviews. \\\n",
    "             This is a technical round, hence you need to ask questions regarding relevant technologies. \\\n",
    "             You may ask some short syntax or a conceptual question. \\\n",
    "             This is the job description: {jd}. \\\n",
    "             This is the candidate's resume: {resume}. \\\n",
    "             This is the past interaction you had with the candidate: {chat_history}. \\\n",
    "             Either ask a review question on candidate's last reponse or ask a new question. \\\n",
    "             Make sure to only ask a single question. \\\n",
    "             The question needs to be relevant to the job description or the candidate's past experience.\"\"\"}])\n",
    "\n",
    "    question=response.choices[0].message.content\n",
    "    return {\"question\":question}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the boss (supervising LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat_history=\"\"\n",
    "\n",
    "\n",
    "tools=[ask_question,store_history]\n",
    "\n",
    "rendered_tools = render_text_description(tools)\n",
    "\n",
    "def handle_interview(state: AgentState) -> AgentState:\n",
    "    print(\"what next?\")\n",
    "    client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_4o_API_KEY\"),  \n",
    "    api_version = os.getenv(\"API_VERSION_4o\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_4o_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "    decision = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"\"\"\n",
    "                You are a corporate interviewer responsible for taking candidate interviews. Decide whether to ask another question or end the conversation.\n",
    "                This is the job description: {jd}.\n",
    "                This is the candidate's resume: {resume}.\n",
    "                This is the past interaction you had with the candidate: {chat_history}.\n",
    "                Respond with 'ask' to ask another question or 'end' to end the conversation.\n",
    "                \"\"\"}]).choices[0].message.content\n",
    "\n",
    "    state[\"decision\"]=decision    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_interaction(state: AgentState) -> AgentState:\n",
    "    # This function should prompt for human input and update the state accordingly\n",
    "    human_decision = input(\"RESPONSE: \")\n",
    "    state['answer'].append(human_decision)\n",
    "    return {\"answer\":human_decision}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph, START, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "from typing import Annotated, Literal, TypedDict,Sequence\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# class AgentState(TypedDict):\n",
    "#     # The add_messages function defines how an update should be processed\n",
    "#     # Default is to replace. add_messages says \"append\"\n",
    "#     messages: str\n",
    "#     decision: str\n",
    "#     question: str\n",
    "#     answer: str\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", handle_interview)  # agent\n",
    "QUESTION = ToolNode([ask_question])\n",
    "workflow.add_node(\"QUESTION\", ask_question) \n",
    "REPORT = ToolNode([get_report])\n",
    "workflow.add_node(\"REPORT\", REPORT)\n",
    "STORE = ToolNode([store_history])\n",
    "workflow.add_node(\"STORE\", STORE) \n",
    "\n",
    "workflow.add_node(\"HUMAN_INTERACTION\", human_interaction)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "def decision_function(state: AgentState) -> Literal[\"QUESTION\", \"STORE\"]:\n",
    "    if state[\"decision\"] == \"ask\":\n",
    "        return \"QUESTION\"\n",
    "    else:\n",
    "        return \"STORE\"\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", decision_function,)\n",
    "\n",
    "workflow.add_edge(\"QUESTION\", \"HUMAN_INTERACTION\")\n",
    "workflow.add_edge(\"HUMAN_INTERACTION\",\"REPORT\")\n",
    "workflow.add_edge(\"REPORT\",\"agent\")\n",
    "workflow.add_edge(\"STORE\", END)\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "# Compile\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what next?\n",
      "\"Node 'agent':\"\n",
      "{'answer': '', 'decision': 'ask', 'messages': 'start interview', 'question': ''}\n",
      "'\\n---\\n'\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ask_questionSchema\nstate\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m inputs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart interview\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecision\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Iterate over the stream of outputs from the graph\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Print the node key\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNode \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1073\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m-> 1073\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1643\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(done, inflight, step)\u001b[0m\n\u001b[0;32m   1641\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m   1642\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m-> 1643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m   1645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m   1646\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m   1648\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\retry.py:72\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     70\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2505\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   2501\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m   2502\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2503\u001b[0m )\n\u001b[0;32m   2504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2505\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2507\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\tools.py:260\u001b[0m, in \u001b[0;36mBaseTool.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, Dict],\n\u001b[0;32m    256\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    259\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m--> 260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\tools.py:417\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n\u001b[1;32m--> 417\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    419\u001b[0m         observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool input validation error\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\tools.py:406\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m    405\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m--> 406\u001b[0m parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[0;32m    408\u001b[0m observation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    414\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\tools.py:304\u001b[0m, in \u001b[0;36mBaseTool._parse_input\u001b[1;34m(self, tool_input)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43minput_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    306\u001b[0m             k: \u001b[38;5;28mgetattr\u001b[39m(result, k)\n\u001b[0;32m    307\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdict()\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    308\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tool_input\n\u001b[0;32m    309\u001b[0m         }\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tool_input\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\v1\\main.py:526\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[1;34m(cls, obj)\u001b[0m\n\u001b[0;32m    524\u001b[0m         exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected dict not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ValidationError([ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY)], \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\BYPB5362\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for ask_questionSchema\nstate\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs={\"messages\":\"start interview\",\"decision\":\"\",\"question\":\"\",\"answer\":\"\"}\n",
    "                            \n",
    "# Iterate over the stream of outputs from the graph\n",
    "for output in graph.stream(inputs,config={\"configurable\": {\"thread_id\": 42}}):\n",
    "    for key, value in output.items():\n",
    "        # Print the node key\n",
    "        pprint(f\"Node '{key}':\")\n",
    "\n",
    "        # Print the value associated with the node (state information)\n",
    "        pprint(value, indent=2, width=80, depth=None)  # Optionally, print full state\n",
    "    pprint(\"\\n---\\n\")  # Separate nodes with a line\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
